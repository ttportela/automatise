{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatize Sample Code\n",
    "\n",
    "Sample Code in python to use Automatize as a python library.\n",
    "\n",
    "[download button]\n",
    "\n",
    "**Observations:**\n",
    "- Not yet compatible with windows, only linux shell\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Paths Configurations\n",
    "You can use configured paths if you want to move directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root     = './'\n",
    "# We consider this folder organization to the experimental enviromnent:\n",
    "prg_path = os.path.join(root, 'programs')\n",
    "data     = os.path.join(root, 'data')\n",
    "res_path = os.path.join(root, 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scripting\n",
    "To run feature extraction methods, import from package `automatize` the script `run.py` or `script.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c0/qm2r5cyd70sbjz8fdkk15k3m0000gn/T/ipykernel_32438/1483822522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from automatize.script import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gensh` function is the statring point to generate scripts for the available methods:\n",
    "\n",
    "- `method`: method name to generate the scripts;\n",
    "- `datasets`: dictionary for datasets config, with\n",
    "    - key: Dataset category folder + . + DAtaset Name (same as Descriptor JSON file prefix)\n",
    "    - value: list of subsets (the second part of JSON descriptor name)\n",
    "- `params`: dictionary of configuration parameters for scripting (described later)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/c0/qm2r5cyd70sbjz8fdkk15k3m0000gn/T/ipykernel_32438/934613619.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m'folder'\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;34m'EXP2022'\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# folder prefix for result files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m'k'\u001b[0m\u001b[0;34m:\u001b[0m         \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0;31m# number of folds - optional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m'root'\u001b[0m\u001b[0;34m:\u001b[0m      \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0;31m# root folder of the experimental environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m'threads'\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;31m# number of threads allowed (for movelets methods) - optional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m'gig'\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0;31m# GB of RAM memory limit allowed (for movelets methods) - optional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'root' is not defined"
     ]
    }
   ],
   "source": [
    "method = 'hiper'\n",
    "datasets = {'multiple_trajectories.FoursquareNYC': ['specific']}\n",
    "\n",
    "params = {\n",
    "    'sh_folder': 'scripts',      # where to generate script files\n",
    "    'folder':    'EXP2022',      # folder prefix for result files\n",
    "    'k':         5,              # number of folds - optional\n",
    "    'root':      root,           # root folder of the experimental environment\n",
    "    'threads':   10,             # number of threads allowed (for movelets methods) - optional\n",
    "    'gig':       100,            # GB of RAM memory limit allowed (for movelets methods) - optional\n",
    "    'pyname': 'python3',         # Python command - optional\n",
    "    \n",
    "    'runopts': '-TR 0.5',        # other arguments to pass to the method line (-TR is the Ï„ for HiPerMovelets) - optional\n",
    "    'timeout': '7d',             # set a timeout to methods runtime (7d limits to 7 days)\n",
    "}\n",
    "\n",
    "gensh(method, datasets, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If, for some reason, you want to join again the results of each class to train.csv / test.csv, you can run the subroutine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mergeAndMove(os.path.join(res_path, prefix, method_name), 'MASTERMovelets', prg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run k-fold experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My Configurations:\n",
    "data_folder = os.path.join(data, 'FoursquareNY')\n",
    "res_path    = os.path.join(root, 'results')\n",
    "prefix      = 'FoursquareNY'\n",
    "method_name = 'Hiper-Log'\n",
    "descriptor  = 'FoursquareNY_specific'\n",
    "k = 5\n",
    "\n",
    "# Print run script:\n",
    "k_run(k, data_folder, res_path, prefix, method_name, descriptor, 'hiper', ms=-1, Ms=-3, extra='-T 0.5', \n",
    "    prg_path=prg_path, print_only=False, keep_folder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print run scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "# My Configurations:\n",
    "data_folder = os.path.join(data, 'scalability')\n",
    "res_path    = os.path.join(root, 'results')\n",
    "\n",
    "prefixes    = ['100_trajectories_50_points', '500_trajectories_50_points', \n",
    "              '1000_trajectories_50_points', '2000_trajectories_50_points', \n",
    "              '4000_trajectories_50_points']\n",
    "\n",
    "jar = 'HIPERMovelets'\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "f = open('Scalability.sh','w')\n",
    "sys.stdout = f\n",
    "print('#!/bin/bash')\n",
    "\n",
    "for j in range(len(prefixes)):\n",
    "    \n",
    "    variation   = 'Vary_Number_Of_Trajectories'\n",
    "    prefix      = prefixes[j]\n",
    "    descriptor  = os.path.join(data_folder, 'descriptors', 'Scalability_1_Dimension')\n",
    "    results_dir = os.path.join(res_path, 'Scalablity', variation)\n",
    "    data_dir    = os.path.join(data_folder, variation)\n",
    "    \n",
    "    run(data_dir, results_dir, prefix, 'Hiper-Log', descriptor, 'hiper', Ms=-3, \\\n",
    "        prg_path=prg_path, print_only=True, java_opts='-Xmx60G', jar_name=jar, n_threads=3)\n",
    "\n",
    "sys.stdout = orig_stdout\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "# My Configurations:\n",
    "k = 5\n",
    "datasets = ['geo_only', 'specific', 'generic', 'poi_only']\n",
    "prefixes = ['brightkite', 'gowalla', 'foursquare_nyc', 'foursquare_global']\n",
    "descriptors = ['Brightkite_Gowalla', 'Brightkite_Gowalla', 'FoursquareNYC', 'FoursquareGlobal']\n",
    "\n",
    "jar = 'SUPERMovelets'\n",
    "methods = [\n",
    "    ['logd', 'SMLD', 'super'],\n",
    "    ['log',  'SML', 'super'],\n",
    "    ['d',    'SMD', 'super'],\n",
    "    ['x',    'SM', 'super'],\n",
    "]\n",
    "extra  = ['-Al true', False, '-Al true', False]\n",
    "Ms     = [-3, -3, False, False]\n",
    "\n",
    "\n",
    "# jar = 'MASTERMovelets'\n",
    "# methods = [\n",
    "#     ['log',  'MML', 'master'],\n",
    "#     ['x',    'MM', 'master'],\n",
    "# ]\n",
    "# extra  = [False, False]\n",
    "# Ms     = [-3, False]\n",
    "\n",
    "for j in range(0, len(methods)):\n",
    "    method = methods[j]\n",
    "    for i in range(0, len(prefixes)):\n",
    "        prefix = prefixes[i]\n",
    "        for dataset in datasets:\n",
    "            if prefix in ['brightkite', 'gowalla'] and dataset is 'generic':\n",
    "                continue\n",
    "            \n",
    "            orig_stdout = sys.stdout\n",
    "            f = open('./scripts/'+method[2]+'/run5-'+method[2]+'_'+method[0]+'-'+prefix+'-'+dataset+'.sh','w')\n",
    "            sys.stdout = f\n",
    "            \n",
    "            print('#!/bin/bash')\n",
    "\n",
    "            descriptor  = os.path.join(data, '5fold', 'descriptors', descriptors[i]+'_'+dataset)\n",
    "            results_dir = os.path.join(res_path, method[2]+'-'+method[0])\n",
    "            data_dir    = os.path.join(data, '5fold', prefix)\n",
    "\n",
    "            k_run(k, data_dir, results_dir, prefix, method[1]+'-'+dataset, descriptor, Ms=Ms[j], extra=extra[j], \\\n",
    "                prg_path=prg_path, print_only=True, java_opts='-Xmx60G', jar_name=jar, n_threads=3)\n",
    "\n",
    "            sys.stdout = orig_stdout\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "\n",
    "# My Configurations:\n",
    "k = 5\n",
    "datasets = ['geo_only', 'specific', 'generic', 'poi_only']\n",
    "prefixes = ['brightkite', 'gowalla', 'foursquare_nyc', 'foursquare_global']\n",
    "descriptors = ['Brightkite_Gowalla', 'Brightkite_Gowalla', 'FoursquareNYC', 'FoursquareGlobal']\n",
    "\n",
    "jar = 'HIPERMovelets'\n",
    "\n",
    "methods = [\n",
    "    ['logp', 'HpL', 'hiper-pvt'],\n",
    "    ['log',  'HL',  'hiper'],\n",
    "    ['p',    'Hp',  'hiper-pvt'],\n",
    "    ['x',    'H',   'hiper'],\n",
    "]\n",
    "Ms     = [-3, -3, False, False]\n",
    "\n",
    "for j in range(0, len(methods)):\n",
    "    method = methods[j]\n",
    "    for i in range(0, len(prefixes)):\n",
    "        prefix = prefixes[i]\n",
    "        for dataset in datasets:\n",
    "            if prefix in ['brightkite', 'gowalla'] and dataset is 'generic':\n",
    "                continue\n",
    "            \n",
    "            orig_stdout = sys.stdout\n",
    "            f = open('./scripts/hiper/run5-hiper_'+method[0]+'-'+prefix+'-'+dataset+'.sh','w')\n",
    "            sys.stdout = f\n",
    "            \n",
    "            print('#!/bin/bash')\n",
    "\n",
    "            descriptor  = os.path.join(data, '5fold', 'descriptors', descriptors[i]+'_'+dataset+'_hp')\n",
    "            results_dir = os.path.join(res_path, 'hiper-'+method[0])\n",
    "            data_dir    = os.path.join(data, '5fold', prefix)\n",
    "\n",
    "            k_run(k, data_dir, results_dir, prefix, method[1]+'-'+dataset, descriptor, method[2], Ms=Ms[j], \\\n",
    "                prg_path=prg_path, print_only=True, java_opts='-Xmx60G', jar_name=jar, n_threads=3)\n",
    "\n",
    "            sys.stdout = orig_stdout\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Classification\n",
    "To run classifiers for the HIPERMovelets results, import from package `automatize` the script analysis.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automatize.analysis import def_random_seed, ACC4All, ALL3, MLP, RF, SVM, results2df, printLatex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines a random and a seed numbers for classifyers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = True\n",
    "\n",
    "def_random_seed(random_num=1, seed_num=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "a. To run the classifyers for each folder inside a result path prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC4All(res_path, prefix, save_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. To run the classifyers for a especific result forder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL3(res_path, prefix, method_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. To run a specific classifyer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(res_path, prefix, method_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "To load the results into an dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = results2df(res_path, prefix)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "To print the dataframe result in a Latex formatted table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printLatex(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pre-processing data\n",
    "To use helpers for data pre-processing, import from package `automatize` the script preprocessing.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automatize.preprocessing import joinTrainAndTest, kfold_trainAndTestSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To join splitted files use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(data, 'foursquare_global')\n",
    "cols = ['tid','label','lat','lon','day','hour','poi','category','price','rating']\n",
    "\n",
    "df = joinTrainAndTest(dir_path, cols, train_file=\"specific_train.csv\", test_file=\"specific_test.csv\", class_col = 'label')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To k-fold split a dataset into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "kfold_trainAndTestSplit(dir_path, k, df, random_num=1, class_col='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# By Tarlis Portela (2020)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
